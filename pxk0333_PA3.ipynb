{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PA 3: Association Analysis - Apriori Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Details\n",
    "\n",
    "Student Name and ID:\n",
    "Pramod Kemisetty, 1001570333, pxk0333"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Instructions\n",
    "\n",
    "\n",
    "Step 1: Create a folder and name it 'yourNetID_PA3'\n",
    "\n",
    "Step 2: Rename this submission file as 'yourNetID_PA3.ipynb' and place it inside the folder 'yourNetID_PA3'\n",
    "\n",
    "Step 3: Rename the updated dataset file 'dataset.csv' and place it inside the folder 'yourNetID_PA3'  \n",
    "\n",
    "Step 4: Your submission folder should include ONLY the following files:\n",
    "    * apriory.py,\n",
    "    * yourNetID_PA3.ipynb, \n",
    "    * dataset.csv,\n",
    "    * toyDS.csv\n",
    "\n",
    "Step 5: Zip this folder and submit it on BB. Your final submission folder name should be 'yourNetID_PA3.ZIP'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming Assignment Details\n",
    "\n",
    "Before you start:\n",
    "- Note that this is an individual assignment.\n",
    "- Be familiar with the algorithm and with the dataset.\n",
    "- If you use external sources make sure that you cite them, and be specific! \n",
    "- Make sure that your code is running before you upload your submission file. TA will not debug your code.\n",
    "- Start early!\n",
    "\n",
    "\n",
    "For this assignment, you will have to use:\n",
    "* Jupyter notebook, \n",
    "* the 'Random Shopping cart' dataset [01],\n",
    "* and the Apriori Algorithm (apriory.py)[02]. Note that the apriory.py file is modified to run with Python 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - - - - - - - - - - - - - - - - - - - - - - - SOLUTION - - - - - - - - - - - - - - - - - - - - - - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your Libraries\n",
    "import pandas as pd\n",
    "import csv\n",
    "import apriori\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: DataSet Preprocess\n",
    "Before you start you need to modify your dataset 'dataset_group.csv' to look like the toyDS.csv.  Each transaction is at one line with a variable length.  Discard the date attribute (1st attribute) from your dataset.  For example, in your dataset transaction#4 should look like: \n",
    "    \n",
    "    cereals,juice,lunch meat,soda,toilet paper,all-purpose\n",
    "\n",
    "Export your modified dataset in a file named 'dataset.csv'.\n",
    "\n",
    "Use pandas to Read and Print the first 7 transactions of the 'dataset.csv'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "print ('ScreenShot of the toyDS.csv')\n",
    "Image(\"SampleScreen01.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # # # # #  Code for Task 1 # # # # # # # # #\n",
    "df = pd.read_csv(\"dataset_group.csv\", sep=',', names = [\"Date\", \"Transactions\", \"Products\"])\n",
    "df.drop(df.columns[0-len(df.columns)],axis = 1, inplace = True)\n",
    "df.head()\n",
    "with open(\"dataset.csv\",'w',newline = '') as finalResult:\n",
    "    wr = csv.writer(finalResult, dialect = 'excel')\n",
    "    for i in range(1,1139):\n",
    "        data = []\n",
    "        for j in range(len(df)):\n",
    "            if(i == df.values[j][0]):\n",
    "                data.append(df.values[j][1])\n",
    "            elif(i+1 == df.values[j][0]):\n",
    "                break\n",
    "        wr.writerow(data)\n",
    "finalResult.close()\n",
    "                \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Run apriory.py and Evaluate Results \n",
    "\n",
    "In this task, you have to find how you will be able to execute and print apriory results by making use only the apriory.py. In other words \"DO NOT USE ANY OTHER LIBRARY FOR TASK 2!!!\". \n",
    "\n",
    "(*) For those that are not familiar with python and coding this could be a quite demanding task.\n",
    "\n",
    "\n",
    "You will have to execute apriori algorithm \"3\" times for different combinations of support and confidence.\n",
    "Print the results of apriory for 'dataset.csv' by making use ONLY the provided methods. \n",
    "\n",
    "Do not forget to add your reasoning (explain the result outcome) at the top of each case in a nice and readable way. \n",
    "\n",
    "You are allowed to use the python print method to print your results. DO NOT add your reasoning as comments. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your Libraries\n",
    "import pandas as pd\n",
    "import csv\n",
    "import apriori\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print ('# # # # # # # # #  Code for Task 2, Case:1 # # # # # # # # #') \n",
    "print ('Case 1 (minimum support=0.40 and minimum confidence=0.85)')\n",
    "print ('Case 1 Reasoning:After many trial and error,I have found that the number of rules generated for the above Support and Confidence are zero.That is, after this, there will be no rules whatsoever.This also sits well with the general thumb rule that higher the value will give no rules.')\n",
    "print ('Case 1 Output: You can find the output below:')\n",
    "%run apriori -f DATASET.csv -s 0.40 -c 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('# # # # # # # # #  Code for Task 2, Case:2 # # # # # # # # #') \n",
    "print ('Case 2 (minimum support=0.2 and minimum confidence=0.4)') \n",
    "print ('Case 1 Reasoning:After many trial and error,I have found that the number of rules generated for the above Support and Confidence are very high.That is, too many rules to accout for the evaluation, which is not advisable.This also sits well with the general thumb rule that lower the value will give way too many rules.')\n",
    "print ('Case 1 Output: You can find the output below:') \n",
    "%run apriori -f DATASET.csv -s 0.2 -c 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('# # # # # # # # #  Code for Task 2, Case:3 # # # # # # # # #') \n",
    "print ('Case 3 (minimum support=0.3 and minimum confidence=0.625)')\n",
    "print ('Case 1 Reasoning:After many trial and error,I have found that the number of rules generated for the above Support and Confidence are moderate.That is, not too many rules to accout for the evaluation, neither very less,which is good for the evaluation.This also sits well with the general thumb rule that the modearte values will give enough rules.')\n",
    "print ('Case 1 Output: You can find the output below:') \n",
    "%run apriori -f DATASET.csv -s 0.3 -c 0.625"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[01] https://www.kaggle.com/acostasg/random-shopping-cart\n",
    "\n",
    "[02] https://github.com/asaini/Apriori\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rubric\n",
    "* [02 points] - Student Details \n",
    "* [08 points] - Comply with submission instructions \n",
    "* [30 points] - DataSet Preprocess \n",
    "* [30 points] - Run apriory.py\n",
    "* [30 points] - Evaluate Results \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
